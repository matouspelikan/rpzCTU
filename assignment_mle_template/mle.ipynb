{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 04 - Maximum Likelihood Parameter Estimation\n",
    "## Pattern Recognition and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and import needed files/methods from previous assignment to this directory. \n",
    "Adding path to the previous assignment is not sufficient. Upload system\n",
    "requires your code to be self contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment following for interactive matplotlib\n",
    "# %matplotlib notebook\n",
    "\n",
    "from mle import *\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_cardinality = 10\n",
    "max_cardinality = 500\n",
    "cardinalities = np.expand_dims(np.arange(step_cardinality,max_cardinality,step_cardinality), 0)\n",
    "n = cardinalities.size\n",
    "\n",
    "var_mu_rec = np.zeros_like(cardinalities, dtype=np.float64)\n",
    "var_sigma_rec = np.zeros_like(cardinalities, dtype=np.float64)\n",
    "\n",
    "for idx in range(n):    \n",
    "    # Compute the variance of the estimations for a fix cardinality\n",
    "    var_mu_rec[0,idx], var_sigma_rec[0,idx] = mle_variance(cardinalities[0,idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(cardinalities.T, var_mu_rec.T, linewidth=3)\n",
    "plt.plot(cardinalities.T, var_sigma_rec.T, linewidth=3)\n",
    "plt.ylim([0, 0.06])\n",
    "plt.legend(['Mean','Standard deviation'])\n",
    "plt.xlabel('Cardinality of traning set')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('MLE variances')\n",
    "plt.grid('on')\n",
    "plt.savefig('mle_variances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from *.mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(data):\n",
    "    \"\"\"\n",
    "    Simple \"hack\" for preparing data from *.mat files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while (len(data) == 1) and (len(data.shape) > 0):\n",
    "            data = data[0]\n",
    "        for key in list(data.dtype.names):\n",
    "            data[key] = unwrap(data[key])\n",
    "    except:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "def ndarray2dict(data, indexes=None):\n",
    "    outputs = {}\n",
    "    for key in list(data.dtype.names):\n",
    "        value = unwrap(data[key])\n",
    "        try:\n",
    "            if len(value.shape) > 0:\n",
    "                value = np.atleast_2d(value)\n",
    "        except:\n",
    "            pass\n",
    "        outputs[key] = value\n",
    "    if indexes is not None:\n",
    "        for key in indexes:\n",
    "            outputs[key] -= 1\n",
    "    return outputs\n",
    "    \n",
    "data = scipy.io.loadmat(\"data_33rpz_04_mle.mat\")\n",
    "Alphabet = np.array(list(unwrap(data[\"Alphabet\"])))\n",
    "tst = ndarray2dict(unwrap(data[\"tst\"]), ['labels'])\n",
    "trn_20 = ndarray2dict(unwrap(data[\"trn_20\"]), ['labels'])\n",
    "trn_200 = ndarray2dict(unwrap(data[\"trn_200\"]), ['labels'])\n",
    "trn_2000 = ndarray2dict(unwrap(data[\"trn_2000\"]), ['labels'])\n",
    "trn_sets = {'20': trn_20, '200': trn_200, '2000': trn_2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training set\n",
    "picked_set = '2000'\n",
    "trn_set = trn_sets[picked_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing features vectors (trainning)\n",
    "x = compute_measurement_lr_cont(trn_set['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate prior probabilities\n",
    "prior_A = estimate_prior(0,trn_set['labels'])\n",
    "prior_C = estimate_prior(1,trn_set['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the trainning data into into classes\n",
    "x_A = x[0:1, trn_set['labels'][0] == 0]\n",
    "x_C = x[0:1, trn_set['labels'][0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Gaussian models of Maximal Likelihood\n",
    "DA = dict()\n",
    "DC = dict()\n",
    "\n",
    "DA['Mean'], DA['Sigma'] = mle_normal(x_A)\n",
    "DC['Mean'], DC['Sigma'] = mle_normal(x_C)\n",
    "\n",
    "DA['Prior'] = prior_A\n",
    "DC['Prior'] = prior_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation\n",
    "\n",
    "Plotting L VS sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([range(200,1000+1)], dtype=np.float64)\n",
    "L, maximizer_sigma, max_L = loglikelihood_sigma(x_C,DC,sigmas)\n",
    "\n",
    "# Plotting the likelihood as a function of Sigma\n",
    "plt.figure()\n",
    "plt.plot(sigmas.T,L.T)\n",
    "plt.grid('on')\n",
    "plt.title('Loglikelihood for varying sigma (class C, $trn_{' + picked_set + '}$)')\n",
    "plt.xlabel('$\\sigma$')\n",
    "plt.ylabel('L($\\sigma$)')\n",
    "plt.plot(maximizer_sigma, max_L, 'r+', markersize=15)\n",
    "plt.plot([DC['Sigma'], DC['Sigma']], [np.min(L), max_L], 'g')\n",
    "plt.savefig('loglikelihood{}.png'.format(picked_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting the aproximated density functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 4000\n",
    "num_bins = 20\n",
    "dom = np.arange(-limit,limit,dtype=np.float64)\n",
    "raise NotImplementedError(\"You have to implement the rest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute histograms\n",
    "hist_A, bin_centers_A = np.histogram(x_A,num_bins)\n",
    "hist_C, bin_centers_C = np.histogram(x_C,num_bins)\n",
    "\n",
    "# Normalize histograms\n",
    "hist_A = hist_A / (np.sum(hist_A) * (bin_centers_A[1]-bin_centers_A[0]))\n",
    "hist_C = hist_C / (np.sum(hist_C) * (bin_centers_C[1]-bin_centers_C[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation for letter A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "plt.figure()\n",
    "plt.bar(bin_centers_A[:-1], hist_A, width=bin_centers_A[1]-bin_centers_A[0] , color='y', edgecolor='k')\n",
    "plt.legend([None])\n",
    "plt.grid('on')\n",
    "plt.title('Densities functions class A')\n",
    "plt.savefig('mle_estimatesA.png')\n",
    "\n",
    "# Overlap estimated distributions\n",
    "raise NotImplementedError(\"You have to implement the rest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation for letter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"You have to implement the rest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the optimal bayesian strategy using the aprox. p.d.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"You have to implement the rest.\")\n",
    "\n",
    "# Computing features vectors (test data)\n",
    "xtst = ...\n",
    "\n",
    "# classify images\n",
    "q_x = ...\n",
    "\n",
    "# classification error\n",
    "error = ...\n",
    "print('Error: {:.2f} %'.format(error * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification(tst['images'], x, 'AC')\n",
    "plt.savefig('mle_classif{}.png'.format(picked_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
